{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gurobipy as gp\n",
    "\n",
    "import scipy.optimize as optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Projection_CappedSimplex(y, s_min=0, s_max=1, S=1):\n",
    "    \"\"\"Projection onto the capped simplex\n",
    "    min_x \\|x - y\\|_2^2 s.t. x \\in [s_min, s_max]^n, <1,x> = S \n",
    "    input: \n",
    "    y - array of length n\n",
    "    s_min - lower bound ( 0 <= s_min )\n",
    "    s_max - upper bound (s_min < s_max)\n",
    "    S - total constarint parameter \\in [s_min*n, s_max*n]\n",
    "            \n",
    "    output:\n",
    "    x - array of length n\n",
    "            \n",
    "    reference:\n",
    "    Weiran Wang: \"Projection onto the capped simplex\". March 3, 2015, arXiv:1503.01002.\n",
    "    \"\"\"\n",
    "            \n",
    "    # Scaling the problem to the following form\n",
    "    # min_x \\|x' - y' \\|_2^2 s.t. x \\in [0, 1]^n, <1,x> = S' \n",
    "    \n",
    "    size = y.shape[0]\n",
    "    \n",
    "    # Scale: Mimimum -> 0\n",
    "    Scaled_S = S - s_min*size\n",
    "    Scaled_s_max = s_max - s_min\n",
    "    y = y - s_min\n",
    "    \n",
    "    # Scale: Maximum -> 1\n",
    "    scaling_parameter = 1/Scaled_s_max\n",
    "    Scaled_S = Scaled_S*scaling_parameter\n",
    "    y=y*scaling_parameter\n",
    "    \n",
    "    # reScale function for return\n",
    "    reScale = lambda x: x/scaling_parameter + s_min\n",
    "    \n",
    "    \n",
    "    # Start the reffered paper's algorithm    \n",
    "    # Check some base case\n",
    "    if Scaled_S > size :\n",
    "        raise ValueError('problem is not feasible')\n",
    "    elif Scaled_S==0:\n",
    "        return reScale(np.zeros(size))\n",
    "    elif Scaled_S==size:\n",
    "        return reScale(np.ones(size))\n",
    "        \n",
    "    # Sort and concatenate to get -infty, y_1, y_2, ..., y_{n}, +infty\n",
    "    idx = np.argsort(y)\n",
    "    \n",
    "    ys = np.concatenate(([-np.inf],y[idx],[np.inf]))\n",
    "    x = np.zeros(size)\n",
    "    \n",
    "    # cumsum and concatenate\n",
    "    T = np.concatenate(([0],np.cumsum(ys[1:])))\n",
    "    # main loop a = 0, ..., n+1\n",
    "    for a in range(0, size+2):\n",
    "        if Scaled_S == (size - a) and ys[a+1] - ys[a] >= 1:\n",
    "            b = a\n",
    "            x[idx] = np.concatenate((np.zeros(a),ys[a+1:b+1] + gamma,np.ones(size-b)))\n",
    "            return reScale(x)\n",
    "        # inner loop b = a+1, ..., n\n",
    "        for b in range(a+1,size+1):\n",
    "            gamma = (Scaled_S + b - size + T[a] - T[b])/(b - a)\n",
    "            if (ys[a] + gamma <= 0) and (ys[a+1] + gamma > 0) and (ys[b] + gamma < 1) and (ys[b+1] + gamma >= 1):\n",
    "                x[idx] = np.concatenate((np.zeros(a),ys[a+1:b+1] + gamma,np.ones(size-b)))\n",
    "                return reScale(x)\n",
    "            \n",
    "            \n",
    "def Projection_CappedSimplex_Opt(y, s_min=0, s_max=1, S=1):\n",
    "    \n",
    "    \"\"\"Projection onto the capped simplex using scipy.optimize\n",
    "    min_x \\|x - y\\|_2^2 s.t. x \\in [s_min, s_max]^n, <1,x> = S \n",
    "    input: \n",
    "    y - array of length n\n",
    "    s_min - lower bound ( 0 <= s_min )\n",
    "    s_max - upper bound (s_min < s_max)\n",
    "    S - total constarint parameter \\in [s_min*n, s_max*n]\n",
    "            \n",
    "    output:\n",
    "    x - array of length n\n",
    "    \"\"\"\n",
    "    \n",
    "    cnst1 = lambda x: x.sum() - S\n",
    "    cnst2 = lambda x: s_max - x \n",
    "    cnst3 = lambda x: x - s_min\n",
    "    \n",
    "    func =  lambda x : (0.5)*(np.linalg.norm(x - y))**2\n",
    "    \n",
    "    \n",
    "    cnst = (\n",
    "          {'type': 'eq', 'fun': cnst1},\n",
    "          {'type': 'ineq', 'fun':cnst2},\n",
    "          {'type': 'ineq', 'fun':cnst3}\n",
    "          )\n",
    "        \n",
    "    result = optimize.minimize(func, y, constraints=cnst)\n",
    "\n",
    "    return result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "y = np.random.rand(N)\n",
    "s_min = 0.1\n",
    "s_max = 0.9\n",
    "S = N*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 164 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_x1 = Projection_CappedSimplex(y, s_min, s_max, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_x2 = Projection_CappedSimplex_Opt(y, s_min, s_max, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6450939817367078"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(new_x1)\n",
    "(np.linalg.norm(new_x1 - y))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6450939817367014"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(new_x2)\n",
    "(np.linalg.norm(new_x2 - y))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(x, y, s_min, s_max, S):\n",
    "    print('s_min <= x', (s_min<=x).all())\n",
    "    print('x <= s_max', (x<=s_max).all())\n",
    "    print('Total=', x.sum())\n",
    "    return 'checked'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s_min <= x True\n",
      "x <= s_max True\n",
      "Total= 499.9999999999999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'checked'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check(new_x1, y, s_min, s_max, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s_min <= x False\n",
      "x <= s_max False\n",
      "Total= 500.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'checked'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check(new_x2, y, s_min, s_max, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
